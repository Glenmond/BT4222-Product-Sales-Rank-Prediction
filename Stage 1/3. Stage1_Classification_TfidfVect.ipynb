{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {},
    "id": "shkwEub9Ng_m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, tree\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "z4fSbRmtNjcs",
    "outputId": "965c2199-8a82-4d50-ee81-121ef00037d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanyh/.pyenv/versions/3.9.2/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('labelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Preprocessing of dataset\n",
    "\n",
    "* Encode the 'label' column to integers\n",
    "\n",
    "* Concatenate summaryClean and reviewCleanLemm to include information on both summary and the actual review itself\n",
    "\n",
    "* Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {},
    "id": "ezWn7nmjNjt0"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['label_cat'] = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {},
    "id": "9K_MbOezTqGz"
   },
   "outputs": [],
   "source": [
    "df['summaryReview'] = df.summaryClean + ' ' + df.reviewCleanLemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {},
    "id": "RK-gAtz0NjxH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['summaryReview']], df['label_cat'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Tuning parameters of TfidfVectorizer\n",
    "\n",
    "Setup an sklearn pipeline, and use LogisticRegression as a basis of comparison for the different sets of hyperparameters. \n",
    "\n",
    "LR is used as it gave the best performance with default parameters when used on TfidfVectorizer with default parameters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "YjTyAP70C5eZ",
    "outputId": "99322df8-2237-49ee-8549-1ad16b082e36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.summaryReview, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "rkiP_3wbC5g7",
    "outputId": "fda78138-7368-4cd6-c4f5-7acdcf213a53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pipeline.predict(X_test.summaryReview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "vyQzj5j9C5jv"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_df': np.linspace(0.00, 0.2, 11)[1:],\n",
    "    'tfidf__min_df': range(3, 11),\n",
    "#     'tfidf__max_features': np.linspace(3000, 10000, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "kzEGbFkXC5l7",
    "outputId": "1d3f562e-a45b-44c9-bcce-b254b0f9bf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "CPU times: user 53.9 s, sys: 22 s, total: 1min 15s\n",
      "Wall time: 13min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tfidf__max_df': array([0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ]),\n",
       "                         'tfidf__min_df': range(3, 11),\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train.summaryReview, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune again with an updated set of parameter space to give more conclusive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "parameters_updated = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "    'tfidf__max_df': np.linspace(0.16, 0.21, 6),\n",
    "    'tfidf__min_df': range(7, 15),\n",
    "#     'tfidf__max_features': np.linspace(3000, 10000, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tfidf__max_df': array([0.16, 0.17, 0.18, 0.19, 0.2 , 0.21]),\n",
       "                         'tfidf__min_df': range(7, 15),\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_updated = GridSearchCV(pipeline, parameters_updated, n_jobs=-1, verbose=5)\n",
    "clf_updated.fit(X_train.summaryReview, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "L2XnwM687kPm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.18, 'tfidf__min_df': 9, 'tfidf__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this parameters, vectorize summaryReview column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_df=0.18, min_df=9, ngram_range=(1, 2))\n",
    "\n",
    "X_train_dtm = tfidf_vect.fit_transform(X_train.summaryReview)\n",
    "X_test_dtm = tfidf_vect.transform(X_test.summaryReview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.18, min_df=9, ngram_range=(1, 2))),\n",
       "                ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_logreg = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer(max_df=0.18, min_df=9, ngram_range=(1, 2))),\n",
    "                     ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_logreg.fit(X_train.summaryReview, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "parameters_logreg = {\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "    'logreg__C': [100, 10, 1.0, 0.1, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.86165333        nan 0.87704           nan 0.87797333\n",
      "        nan 0.822             nan 0.75938667]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 19.8 s, total: 35.4 s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(max_df=0.18, min_df=9,\n",
       "                                                        ngram_range=(1, 2))),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logreg__C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'logreg__penalty': ['l1', 'l2']},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_logreg = GridSearchCV(pipeline_logreg, parameters_logreg, n_jobs=-1, verbose=5)\n",
    "clf_logreg.fit(X_train.summaryReview, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 1.0, 'logreg__penalty': 'l2'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanyh/.pyenv/versions/3.9.2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87592"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1, penalty='l2')\n",
    "\n",
    "lr.fit(X_train_dtm, y_train)\n",
    "\n",
    "metrics.accuracy_score(y_test, lr.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: user 20min 15s, sys: 254 ms, total: 20min 15s\n",
      "Wall time: 2h 4min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svm_params = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "sv = svm.SVC()\n",
    "\n",
    "svm_clf = GridSearchCV(sv, svm_params, verbose=5, n_jobs=-1)\n",
    "svm_clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "PXwkRhRcStEb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {},
    "id": "pdGPcJgBStHh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = svm.SVC(C=100, gamma=1)\n",
    "\n",
    "sv.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "4Kbrf2seStKp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, sv.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "DzrwbsmGStN8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86344"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "metrics.accuracy_score(y_test, nb.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "Yv7Y2YGCAJKK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 17 candidates, totalling 85 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [1000, 500, 100, 50, 10, 7, 6, 5, 4, 2, 1,\n",
       "                                   0.5, 0.1, 0.05, 0.01, 0.005, 0.001]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_params = {\n",
    "    'alpha': [1000,500,100,50,10,7,6,5,4,2,1,0.5,0.1,0.05,0.01,0.005,0.001]\n",
    "}\n",
    "\n",
    "clf_nb = GridSearchCV(nb, nb_params, verbose=5, n_jobs=-1)\n",
    "clf_nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "A0P7N1V3AJM7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {},
    "id": "maaVqnaGAJPj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.1)\n",
    "\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "metrics.accuracy_score(y_test, nb.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2giNjJjUAJR-"
   },
   "source": [
    "### Tune XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "JLHrJ1-UAJU7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 2min 2s, sys: 337 ms, total: 2min 2s\n",
      "Wall time: 58min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(7, 17, 2),\n",
       "                         'min_child_weight': range(3, 13, 2)},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xg_params = {'max_depth': range(7,17,2), \n",
    "             'min_child_weight': range(3,13,2)\n",
    "            }\n",
    "\n",
    "xg = XGBClassifier()\n",
    "\n",
    "xg_clf = GridSearchCV(xg, xg_params, verbose=5, n_jobs=-1)\n",
    "xg_clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'min_child_weight': 7}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:47:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 2min 13s, sys: 262 ms, total: 2min 14s\n",
      "Wall time: 14min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(15, 23, 2),\n",
       "                         'min_child_weight': [7]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xg_params_updated = {'max_depth': range(15,23,2), \n",
    "             'min_child_weight': [7]\n",
    "            }\n",
    "\n",
    "xg = XGBClassifier()\n",
    "\n",
    "xg_clf_updated = GridSearchCV(xg, xg_params_updated, verbose=5, n_jobs=-1)\n",
    "xg_clf_updated.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 17, 'min_child_weight': 7}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf_updated.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanyh/.pyenv/versions/3.9.2/lib/python3.9/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier(max_depth=17, min_child_weight=7)\n",
    "\n",
    "xg.fit(X_train_dtm, y_train)\n",
    "\n",
    "metrics.accuracy_score(y_test, xg.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Tuning Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "CPU times: user 38.7 s, sys: 6.19 s, total: 44.9 s\n",
      "Wall time: 39min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 10, 15, 20, 25, 30],\n",
       "                         'min_samples_leaf': [1, 2, 5, 10],\n",
       "                         'min_samples_split': [2, 3, 5, 7, 9, 15, 30, 50, 100],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dt_params = {'criterion': ['gini', 'entropy'], \n",
    "             'splitter': ['best', 'random'], \n",
    "             'max_depth': [2, 3, 4, 5, 10, 15, 20, 25, 30], \n",
    "             'min_samples_split': [2, 3, 5, 7, 9, 15, 30, 50, 100],\n",
    "             'min_samples_leaf': [1, 2, 5, 10],\n",
    "            }\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt_clf = GridSearchCV(dt, dt_params, verbose=5, n_jobs=-1)\n",
    "dt_clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 30,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 100,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82752"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', max_depth=30, min_samples_leaf=5, min_samples_split=100, splitter='random')\n",
    "\n",
    "dt.fit(X_train_dtm, y_train)\n",
    "\n",
    "metrics.accuracy_score(y_test, dt.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Tuning KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "CPU times: user 1.7 s, sys: 469 ms, total: 2.17 s\n",
      "Wall time: 7min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67,\n",
       "       69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99])},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "knn_params = {'n_neighbors': np.arange(1,100,2)}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_clf = GridSearchCV(knn, knn_params, verbose=5, n_jobs=-1)\n",
    "knn_clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 17}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "knn.fit(X_train_dtm, y_train)\n",
    "\n",
    "metrics.accuracy_score(y_test, knn.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {}
   },
   "source": [
    "# Stacking models\n",
    "\n",
    "Stack the base models, and develop a meta learner to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('lr', lr),\n",
    "    ('sv', sv),\n",
    "    ('nb', nb),\n",
    "    ('xg', xg),\n",
    "#     ('dt', dt),\n",
    "#     ('knn', knn)\n",
    "]\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "# meta_model = XGBClassifier()\n",
    "# cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=4222)\n",
    "\n",
    "# stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=cv, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 292 ms, total: 558 ms\n",
      "Wall time: 35min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr', LogisticRegression(C=1)),\n",
       "                               ('sv', SVC(C=100, gamma=1)),\n",
       "                               ('nb', MultinomialNB(alpha=0.1)),\n",
       "                               ('xg',\n",
       "                                XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=1, gamma=0,\n",
       "                                              gpu_id=-1, importance_type='gain',\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.300000012,\n",
       "                                              max_delta_step=0, max_depth=17,\n",
       "                                              min_child_weight=7, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=100, n_jobs=8,\n",
       "                                              num_parallel_tree=1,\n",
       "                                              random_state=0, reg_alpha=0,\n",
       "                                              reg_lambda=1, scale_pos_weight=1,\n",
       "                                              subsample=1, tree_method='exact',\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=None))],\n",
       "                   final_estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1, verbose=5)\n",
    "stacked_model.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88704"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model.score(X_test_dtm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 s, sys: 461 ms, total: 20.9 s\n",
      "Wall time: 31min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr', LogisticRegression(C=1)),\n",
       "                               ('sv', SVC(C=100, gamma=1)),\n",
       "                               ('nb', MultinomialNB(alpha=0.1)),\n",
       "                               ('xg',\n",
       "                                XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=1, gamma=0,\n",
       "                                              gpu_id=-1, importance_type='gain',\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.300000012,\n",
       "                                              max_delta_step=0, max_depth=17,\n",
       "                                              min_child_weight=7, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=100, n_jobs=8,\n",
       "                                              num_parallel_tree=1,\n",
       "                                              random_state=0, reg_alpha=0,\n",
       "                                              reg_lambda=1, scale_pos_weight=1,\n",
       "                                              subsample=1, tree_method='exact',\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=None))],\n",
       "                   final_estimator=SVC(), n_jobs=-1, verbose=5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stacked_model_svm = StackingClassifier(estimators=base_models, final_estimator=svm.SVC(), n_jobs=-1, verbose=5)\n",
    "stacked_model_svm.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88704"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model_svm.score(X_test_dtm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(models, model_names):\n",
    "    #create empty df with col names\n",
    "    df = pd.DataFrame(columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'ROC AUC'])\n",
    "    \n",
    "    for n, model in enumerate(models):\n",
    "\n",
    "        y_pred = model.predict(X_test_dtm)\n",
    "\n",
    "        name = model_names[n]\n",
    "        \n",
    "        acc = metrics.accuracy_score(y_test, y_pred)\n",
    "        prec = metrics.precision_score(y_test, y_pred)\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        f1 = metrics.f1_score(y_test, y_pred)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        #append row to df\n",
    "        df = df.append(\n",
    "            {\n",
    "                'Model' : name,\n",
    "                'Accuracy': acc,\n",
    "                'Precision': prec,\n",
    "                'Recall': recall,\n",
    "                'F1 score': f1,\n",
    "                'ROC AUC': roc_auc\n",
    "            }, ignore_index = True)\n",
    "            \n",
    "    return df.set_index('Model').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>lr</th>\n",
       "      <th>sv</th>\n",
       "      <th>nb</th>\n",
       "      <th>xg</th>\n",
       "      <th>dt</th>\n",
       "      <th>knn</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.875920</td>\n",
       "      <td>0.883440</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.868080</td>\n",
       "      <td>0.827520</td>\n",
       "      <td>0.821200</td>\n",
       "      <td>0.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.885764</td>\n",
       "      <td>0.898831</td>\n",
       "      <td>0.885737</td>\n",
       "      <td>0.888548</td>\n",
       "      <td>0.847499</td>\n",
       "      <td>0.844383</td>\n",
       "      <td>0.906080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.960766</td>\n",
       "      <td>0.954139</td>\n",
       "      <td>0.945829</td>\n",
       "      <td>0.945093</td>\n",
       "      <td>0.942884</td>\n",
       "      <td>0.937730</td>\n",
       "      <td>0.943726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>0.921742</td>\n",
       "      <td>0.925659</td>\n",
       "      <td>0.914797</td>\n",
       "      <td>0.915949</td>\n",
       "      <td>0.892651</td>\n",
       "      <td>0.888612</td>\n",
       "      <td>0.924520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.783590</td>\n",
       "      <td>0.806505</td>\n",
       "      <td>0.779129</td>\n",
       "      <td>0.784274</td>\n",
       "      <td>0.701980</td>\n",
       "      <td>0.694391</td>\n",
       "      <td>0.816500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            lr        sv        nb        xg        dt       knn  \\\n",
       "Accuracy   0.875920  0.883440  0.866000  0.868080  0.827520  0.821200   \n",
       "Precision  0.885764  0.898831  0.885737  0.888548  0.847499  0.844383   \n",
       "Recall     0.960766  0.954139  0.945829  0.945093  0.942884  0.937730   \n",
       "F1 score   0.921742  0.925659  0.914797  0.915949  0.892651  0.888612   \n",
       "ROC AUC    0.783590  0.806505  0.779129  0.784274  0.701980  0.694391   \n",
       "\n",
       "Model         stack  \n",
       "Accuracy   0.882800  \n",
       "Precision  0.906080  \n",
       "Recall     0.943726  \n",
       "F1 score   0.924520  \n",
       "ROC AUC    0.816500  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance([lr, sv, nb, xg, dt, knn, stacked_model], ['lr', 'sv', 'nb', 'xg', 'dt', 'knn', 'stack'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
