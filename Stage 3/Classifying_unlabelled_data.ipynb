{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.4.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.16)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (7.0.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (4.5.1.48)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (8.1.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.11.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (3.3.3)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (1.2.2)\n",
      "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (2.4.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (1.1.5)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (4.2.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (2.1.0)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.29.22)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.1.95)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.12.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.8)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (1.5.12)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (2.13.1)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official) (5.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official) (3.14.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval->tf-models-official) (0.24.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.11.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.32.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.4.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->tf-models-official) (2021.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (20.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (4.59.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.3)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (0.18.2)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (5.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (2.25.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official) (0.29.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.19.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.0)\n",
      "Requirement already satisfied: google-auth<2dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.24.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tf-models-official) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official) (2.12.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.26.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official) (2020.12.5)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.0.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (1.18.1)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (1.2.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (1.6.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (20.8)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->tf-models-official) (51.3.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (2.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-official) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-official) (4.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official) (1.14.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official) (2.20)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub\n",
    "!pip install keras tf-models-official pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Version:  2.4.1\n",
      "Eager mode:  True\n",
      "Hub version:  0.11.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization as tokenization\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "os.chdir('/notebooks/Data')\n",
    "combined_df = pd.read_csv('Combined_sentiment_analysis.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "combined_df = combined_df.rename(columns={'ï»¿Datetime': 'Datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>TextClean</th>\n",
       "      <th>TextCleanLemm</th>\n",
       "      <th>tb_score</th>\n",
       "      <th>afinn_score</th>\n",
       "      <th>vader_com</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>Brand</th>\n",
       "      <th>wkd_value</th>\n",
       "      <th>wkd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-10-01 23:59:47+00:00</td>\n",
       "      <td>3.851924e+17</td>\n",
       "      <td>TRIPP LITE 6SP 6 Outlets Power Strip $28.99 ht...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tripp lite sp outlets power strip</td>\n",
       "      <td>tripp lite sp outlet power strip</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>TrippLite</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-10-01 23:17:54+00:00</td>\n",
       "      <td>3.851818e+17</td>\n",
       "      <td>2yr Warranty Bonus-Tripplite Tripp Lite v1.3 2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yr warranty bonus tripplite tripp lite v port ...</td>\n",
       "      <td>yr warranty bonus tripplite tripp lite v port ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.696</td>\n",
       "      <td>TrippLite</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-10-01 23:17:22+00:00</td>\n",
       "      <td>3.851817e+17</td>\n",
       "      <td>Tripp Lite Lite ProtectIT SUPER7COAX 120VAC Su...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tripp lite lite protectit super coax vac surge...</td>\n",
       "      <td>tripp lite lite protectit super coax vac surge...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.719</td>\n",
       "      <td>TrippLite</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-10-01 23:13:22+00:00</td>\n",
       "      <td>3.851807e+17</td>\n",
       "      <td>Tripp Lite Surge Protector Strip 120V 6 Outlet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tripp lite surge protector strip v outlet ft c...</td>\n",
       "      <td>tripp lite surge protector strip v outlet ft c...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>TrippLite</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-10-01 22:54:06+00:00</td>\n",
       "      <td>3.851758e+17</td>\n",
       "      <td>Tripp Lite P516-001 VGA/XVGA Monitor Y Splitte...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tripp lite p vga xvga monitor splitter hd xf</td>\n",
       "      <td>tripp lite p vga xvga monitor splitter hd xf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>TrippLite</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime      Tweet Id  \\\n",
       "0 2013-10-01 23:59:47+00:00  3.851924e+17   \n",
       "1 2013-10-01 23:17:54+00:00  3.851818e+17   \n",
       "2 2013-10-01 23:17:22+00:00  3.851817e+17   \n",
       "3 2013-10-01 23:13:22+00:00  3.851807e+17   \n",
       "4 2013-10-01 22:54:06+00:00  3.851758e+17   \n",
       "\n",
       "                                                Text  Retweets  LikeCount  \\\n",
       "0  TRIPP LITE 6SP 6 Outlets Power Strip $28.99 ht...       0.0        0.0   \n",
       "1  2yr Warranty Bonus-Tripplite Tripp Lite v1.3 2...       0.0        0.0   \n",
       "2  Tripp Lite Lite ProtectIT SUPER7COAX 120VAC Su...       0.0        0.0   \n",
       "3  Tripp Lite Surge Protector Strip 120V 6 Outlet...       0.0        0.0   \n",
       "4  Tripp Lite P516-001 VGA/XVGA Monitor Y Splitte...       0.0        0.0   \n",
       "\n",
       "   QuoteCount                                          TextClean  \\\n",
       "0         0.0                  tripp lite sp outlets power strip   \n",
       "1         0.0  yr warranty bonus tripplite tripp lite v port ...   \n",
       "2         0.0  tripp lite lite protectit super coax vac surge...   \n",
       "3         0.0  tripp lite surge protector strip v outlet ft c...   \n",
       "4         0.0       tripp lite p vga xvga monitor splitter hd xf   \n",
       "\n",
       "                                       TextCleanLemm  tb_score  afinn_score  \\\n",
       "0                   tripp lite sp outlet power strip  0.000000          0.0   \n",
       "1  yr warranty bonus tripplite tripp lite v port ...  0.000000          0.0   \n",
       "2  tripp lite lite protectit super coax vac surge...  0.333333          3.0   \n",
       "3  tripp lite surge protector strip v outlet ft c... -0.166667          0.0   \n",
       "4       tripp lite p vga xvga monitor splitter hd xf  0.000000          0.0   \n",
       "\n",
       "   vader_com  vader_pos  vader_neg  vader_neu      Brand  wkd_value  wkd  \n",
       "0     0.0000      0.000       -0.0      1.000  TrippLite          1  Tue  \n",
       "1     0.5423      0.304       -0.0      0.696  TrippLite          1  Tue  \n",
       "2     0.5994      0.281       -0.0      0.719  TrippLite          1  Tue  \n",
       "3     0.0000      0.000       -0.0      1.000  TrippLite          1  Tue  \n",
       "4     0.0000      0.000       -0.0      1.000  TrippLite          1  Tue  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Datetime'] = pd.to_datetime(combined_df['Datetime'])\n",
    "\n",
    "combined_df['wkd_value'] = combined_df['Datetime'].dt.dayofweek\n",
    "\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (combined_df['wkd_value'] == 0),\n",
    "    (combined_df['wkd_value'] == 1),\n",
    "    (combined_df['wkd_value'] == 2),\n",
    "    (combined_df['wkd_value'] == 3),\n",
    "    (combined_df['wkd_value'] == 4),\n",
    "    (combined_df['wkd_value'] == 5),\n",
    "    (combined_df['wkd_value'] == 6)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "combined_df['wkd'] = np.select(conditions, values)\n",
    "\n",
    "# display updated DataFrame\n",
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "os.chdir('/notebooks/BERT_model')\n",
    "encoder_fname = 'twitter_classes.npy'\n",
    "my_wd = os.getcwd()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load(os.path.join(my_wd, encoder_fname), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "os.chdir('/notebooks/BERT_model')\n",
    "encoder_fname = 'twitter_wkd.npy'\n",
    "my_wd = os.getcwd()\n",
    "\n",
    "featureEncoderSaved = LabelEncoder()\n",
    "featureEncoderSaved.classes_ = np.load(os.path.join(my_wd, encoder_fname), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun    43835\n",
      "Sat    44176\n",
      "Mon    45984\n",
      "Thu    46395\n",
      "Fri    46732\n",
      "Wed    46822\n",
      "Tue    47328\n",
      "Name: wkd, dtype: int64\n",
      "[0 4]\n",
      "['Fri' 'Mon' 'Sat' 'Sun' 'Thu' 'Tue' 'Wed']\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "print(combined_df['wkd'].value_counts(ascending=True))\n",
    "\n",
    "print(encoder.classes_)\n",
    "\n",
    "print(featureEncoderSaved.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#os.chdir('/notebooks/BERT_model')\n",
    "#with zipfile.ZipFile('/notebooks/twitter_BERT_wWKD.zip', 'r') as zip_ref:\n",
    "#    zip_ref.extractall('/notebooks/BERT_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "os.chdir('/notebooks/BERT_model')\n",
    "model_fname = 'twitter_BERT_wWKD'\n",
    "my_wd = os.getcwd()\n",
    "\n",
    "tokenizerSaved = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(my_wd, model_fname, 'assets/vocab.txt'),\n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-03cfc19dbe43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_wd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   raise IOError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mnodes_to_load\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m   \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;31m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0mto\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m   \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m--> 890\u001b[0;31m                             ckpt_options, filters)\n\u001b[0m\u001b[1;32m    891\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         raise FileNotFoundError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, filters)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                   self._checkpoint_options).expect_partial()\n\u001b[1;32m    486\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         options=options)\n\u001b[1;32m   1336\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1337\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[0;31m# Attached dependencies are not attached to the root, so should be restored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    971\u001b[0m     restore_ops.extend(\n\u001b[1;32m    972\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[0;32m--> 973\u001b[0;31m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    306\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m    307\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0;32m--> 308\u001b[0;31m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m           \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[1;32m    115\u001b[0m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0;32m--> 116\u001b[0;31m           restored_tensors, restored_shapes=None)\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Copy the restored tensor to the variable's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0mrestored_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[1;32m    132\u001b[0m           self.handle_op, self._var_shape, restored_tensor)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3931\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3932\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3933\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3934\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(os.path.join(my_wd, model_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def encode_names(n, tokenizer):\n",
    "   tokens = list(tokenizer.tokenize(n))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def bert_encode(string_list,\n",
    "                tokenizer, \n",
    "                new_feature,  # [NEW]\n",
    "                new_feature_class_count,  # [NEW] \n",
    "                max_seq_length):  \n",
    "  num_examples = len(string_list)\n",
    "  \n",
    "  string_tokens = tf.ragged.constant([\n",
    "      encode_names(n, tokenizer) for n in np.array(string_list)])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*string_tokens.shape[0]\n",
    "  input_word_ids = tf.concat([cls, string_tokens], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_tokens = tf.ones_like(string_tokens)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_tokens], axis=-1).to_tensor(shape=(None, max_seq_length))\n",
    "  feature = tf.ragged.constant(new_feature).to_tensor(shape=(None, new_feature_class_count))  # [NEW]\n",
    "\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor(shape=(None, max_seq_length)),\n",
    "      'input_mask': input_mask,\n",
    "      'input_type_ids': input_type_ids,\n",
    "      'additional_feature': feature}  # [NEW]\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BossAudio        460\n",
      "Sony            4446\n",
      "Pwr+            6237\n",
      "TrippLite       6273\n",
      "Garmin          6326\n",
      "PolkAudio       6335\n",
      "Sangean         6446\n",
      "Belkin          6499\n",
      "Apple           7129\n",
      "YamahaAudio    14103\n",
      "Name: Brand, dtype: int64\n",
      "(64254, 18)\n"
     ]
    }
   ],
   "source": [
    "sample_size = int(len(combined_df)*0.2)\n",
    "sampleDf = combined_df.sample(sample_size, random_state=4222)\n",
    "print(sampleDf.Brand.value_counts(ascending=True))\n",
    "sampleDf = sampleDf.reset_index()\n",
    "print(sampleDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "LOG_EVERY_N = 100\n",
    "result = []\n",
    "for i in range(len(sampleDf)):\n",
    "  tweet = [sampleDf['TextCleanLemm'][i]]\n",
    "  wkd = [sampleDf['wkd'][i]]\n",
    "\n",
    "  dummy_wkd = np_utils.to_categorical(featureEncoderSaved.transform(np.array(wkd)))  # encodes weekday\n",
    "\n",
    "  inputs = bert_encode(string_list=list(tweet),\n",
    "                      tokenizer=tokenizerSaved,\n",
    "                      new_feature=dummy_wkd,\n",
    "                      new_feature_class_count=7,\n",
    "                      max_seq_length=240)\n",
    "  prediction = new_model.predict(inputs)\n",
    "  if (encoder.classes_[np.argmax(prediction)]==4) == True:\n",
    "    result.append(1)\n",
    "  else:\n",
    "    result.append(0)\n",
    "  if (i % LOG_EVERY_N) == 0:\n",
    "    print('Tweet ', i, ' is', 'positive' if encoder.classes_[np.argmax(prediction)]==4 else 'negative')\n",
    "  else:\n",
    "    continue\n",
    "\n",
    "sampleDf[\"Sentiment\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "os.chdir('/notebooks/Data')\n",
    "sampleDf.to_csv(\"Brand_BERT_sentiment2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
